{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'torch'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m~/util/example.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutil_torch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_find_lr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutil_torch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_tensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutil_torch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_tensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/util/util_torch/torch_find_lr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"]}],"source":["import time\n","import json\n","import random\n","from pathlib import Path\n","from datetime import datetime\n","from itertools import product\n","from collections import namedtuple\n","from collections import OrderedDict\n","from PIL import Image\n","\n","from util_torch.torch_find_lr import find_lr\n","from util_torch.my_tensorboard import RunManager\n","from util_torch.my_tensorboard import RunBuilder\n","from util_torch.torch_datasplit import make_directory_split\n","from util_torch.torch_datasplit import DataSplit\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import Dataset\n","import librosa\n","import librosa.display\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","class Timer:\n","    def __init__(self):\n","        self.start = time.time()\n","\n","    def restart(self):\n","        self.start = time.time()\n","\n","    def get_time_hhmmss(self):\n","        end = time.time()\n","        m, s = divmod(end - self.start, 60)\n","        h, m = divmod(m, 60)\n","        time_str = f\"{h:02.0f}:{m:02.0f}:{s:02.0f}\"\n","        return time_str\n","\n","\n","def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n","    for epoch in range(epochs):\n","        training_loss = 0.0\n","        valid_loss = 0.0\n","        model.train()\n","        for batch in train_loader:\n","            optimizer.zero_grad()\n","            inputs, targets = batch\n","            inputs = inputs.to(device)\n","            targets = targets.to(device)\n","            output = model(inputs)\n","            loss = loss_fn(output, targets)\n","            loss.backward()\n","            optimizer.step()\n","            training_loss += loss.data.item() * inputs.size(0)\n","        training_loss /= len(train_loader.dataset)\n","\n","        model.eval()\n","        num_correct = 0\n","        num_examples = 0\n","        for batch in val_loader:\n","            inputs, targets = batch\n","            inputs = inputs.to(device)\n","            targets = targets.to(device)\n","            output = model(inputs)\n","            loss = loss_fn(output, targets)\n","            valid_loss += loss.data.item() * inputs.size(0)\n","            correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n","            num_correct += torch.sum(correct).item()\n","            num_examples += correct.shape[0]\n","        valid_loss /= len(val_loader.dataset)\n","\n","        print(\n","            f\"Epoch: {epoch}, Training Loss: {training_loss:.3f}, \\\n","            Validation Loss: {valid_loss:.3f}, \\\n","            accuracy = {num_correct / num_examples:.3f}\"\n","        )\n","\n","\n","PATH_TO_MNIST = Path.cwd() / \"MNIST\"\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# dataset = torchvision.datasets.MNIST(\n","#     PATH_TO_MNIST,\n","#     train=True,\n","#     download=True,\n","#     transform=transforms.Compose(\n","#         [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n","#     ),\n","# )\n","\n","\n","def precompute_spectrogram(path, dpi=50):\n","    files = Path(path).glob(\"*.wav\")\n","    for filename in files:\n","        audio_tensor, sample_rate = librosa.load(filename, sr=None)\n","        spectrogram = librosa.feature.melspectrogram(audio_tensor, sr=sample_rate)\n","        log_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n","        librosa.display.specshow(\n","            log_spectrogram, sr=sample_rate, x_axis=\"time\", y_axis=\"mel\"\n","        )\n","        plt.gcf().savefig(f\"{filename.parent}/{dpi}_{filename.name}.png\", dpi=dpi)\n","\n","\n","class FrequencyMask(object):\n","    \"\"\"\n","      Example:\n","        >>> transforms.Compose([\n","            transforms.ToTensor(),\n","            FrequencyMask(max_width=10, use_maen=False),\n","        ])\n","    \"\"\"\n","\n","    def __init__(self, max_width, use_mean=True):\n","        self.max_width = max_width\n","        self.use_mean = use_mean\n","\n","    def __call__(self, tensor):\n","        \"\"\"\n","        Args:\n","            tensor (Tensor): Tensor image of size (C, H, W) where \n","            the frequency mask is to be applied.\n","\n","        Returns:\n","            Tensor: Transformed image with Frequency Mask.\n","        \"\"\"\n","        start = random.randrange(0, tensor.shape[2])\n","        end = start + random.randrange(1, self.max_width)\n","        if self.use_mean:\n","            tensor[:, start:end, :] = tensor.mean()\n","        else:\n","            tensor[:, start:end, :] = 0\n","        return tensor\n","\n","    def __repr__(self):\n","        # format_string = self.__class__.__name__ + \"(max_width=\"\n","        # format_string += str(self.max_width) + \")\"\n","        # format_string += 'use_mean=' + (str(self.use_mean) + ')')\n","\n","        # return format_string\n","        return f\"{self.__class__.name}(max_width={str(self.max_width)}, use_mean={str(self.use_mean)})\"\n","\n","\n","class TimeMask(object):\n","    \"\"\"\n","        Example:\n","        >>> transforms.Compose([\n","                transforms.ToTensor(),\n","                TimeMask(max_widht=10, use_mean=False),\n","        ])\n","    \"\"\"\n","\n","    def __init__(self, max_width, use_mean=True):\n","        self.max_width = max_width\n","        self.use_mean = use_mean\n","\n","    def __call__(self, tensor):\n","        \"\"\"\n","        Args:\n","            tensor (Tensor): Tensor image of size (C, H, W)\n","            where the time mask is to be applied.\n","        \n","        Returns:\n","            Tensor: Transformed image iwth Time Mask.\n","\n","        \"\"\"\n","        start = random.randrange(0, tensor.shape[1])\n","        end = start + random.randrange(0, self.max_width)\n","        if self.use_mean:\n","            tensor[:, :, start:end] = tensor.mean()\n","        else:\n","            tensor[:, :, start:end] = 0\n","        return tensor\n","\n","    def __repr__(self):\n","\n","        return f\"{self.__class__.__name__}'(max_width='{str(self.max_width)})'use_mean='{str(self.use_mean)})\"\n","\n","\n","class PrecomputedTransformESC50(Dataset):\n","    def __init__(\n","        self,\n","        path,\n","        max_freqmask_width,\n","        max_timemask_width,\n","        img_transforms=None,\n","        use_mean=True,\n","        dpi=50,\n","    ):\n","\n","        files = Path(path).glob(f\"{dpi}*.wav.png\")\n","        self.items = [\n","            (f, int(f.name.split(\"-\")[-1].replace(\".wav.png\", \"\"))) for f in files\n","        ]\n","        self.length = len(self.items)\n","        self.max_freqmask_width = max_freqmask_width\n","        self.max_timemask_width = max_timemask_width\n","        self.use_mean = use_mean\n","        if img_transforms == None:\n","            self.img_transforms = transforms.Compose(\n","                [\n","                    transforms.ToTensor(),\n","                    transforms.Normalize(\n","                        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n","                    ),\n","                    transforms.RandomApply(\n","                        [FrequencyMask(self.max_freqmask_width, self.use_mean)], p=0.5\n","                    ),\n","                    transforms.RandomApply(\n","                        [TimeMask(self.max_timemask_width, self.use_mean)], p=0.5\n","                    ),\n","                ]\n","            )\n","        else:\n","            self.img_transforms = img_transforms\n","\n","    def __getitem__(self, index):\n","        filename, label = self.items[index]\n","        img = Image.open(filename).convert(\"RGB\")\n","        return (self.img_transforms(img), label)\n","\n","    def __len__(self):\n","        return self.length\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Timer' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m~/util/example.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprecompute_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"ESC-50\"\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"audio\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mPATH_TO_ESC50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"ESC-50\"\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"audio\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"precompute spectrogram: {timer.get_time_hhmmss()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Timer' is not defined"]}],"source":["timer = Timer()\n","precompute_spectrogram(Path.cwd() / \"ESC-50\" / \"audio\")\n","PATH_TO_ESC50 = Path.cwd() / \"ESC-50\" / \"audio\"\n","print(f\"precompute spectrogram: {timer.get_time_hhmmss()}\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'timer' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m~/util/example.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# trian, val, test 디렉토리 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_directory_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_ESC50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# png 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mPATH_ESC50_TRAIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPATH_TO_ESC50\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'timer' is not defined"]}],"source":["# trian, val, test 디렉토리 생성\n","timer.restart()\n","split = make_directory_split(PATH_TO_ESC50)\n","# png 생성\n","PATH_ESC50_TRAIN = PATH_TO_ESC50 / \"train\"\n","PATH_ESC50_VAL = PATH_TO_ESC50 / \"validation\"\n","print(f\"make_directory_split: {timer.get_time_hhmmss()}\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'PrecomputedTransformESC50' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m~/util/example.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m esc50pre_train = PrecomputedTransformESC50(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mPATH_ESC50_TRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_freqmask_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_timemask_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m esc50pre_val = PrecomputedTransformESC50(\n","\u001b[0;31mNameError\u001b[0m: name 'PrecomputedTransformESC50' is not defined"]}],"source":["esc50pre_train = PrecomputedTransformESC50(\n","    PATH_ESC50_TRAIN, max_freqmask_width=10, max_timemask_width=10,\n",")\n","timer.restart()\n","esc50pre_val = PrecomputedTransformESC50(\n","    PATH_ESC50_VAL, max_freqmask_width=10, max_timemask_width=10\n",")\n","\n","esc50_train_loader = torch.utils.data.DataLoader(esc50pre_train, 32, shuffle=True)\n","esc50_val_loader = torch.utils.data.DataLoader(esc50pre_val, 32, shuffle=True)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'torchvision' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m~/util/example.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# find initial leraning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"bn\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"]}],"source":["# find initial leraning rate \n","model = torchvision.models.resnet50(True)\n","for name, param in model.named_parameters():\n","    if \"bn\" not in name:\n","        param.requires_grad = False\n","\n","model.fc = nn.Sequential(\n","    nn.Linear(model.fc.in_features, 500), nn.ReLU(), nn.Dropout(), nn.Linear(500, 50),\n",")\n","model.to(device)\n","torch.save(model.state_dict(), \"model_resnet50.pth\")\n","loss_fn = nn.CrossEntropyLoss()\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","lrs, losses = find_lr(model, loss_fn, optimizer, esc50_train_loader, device=device)\n","plt.plot(lrs, losses)\n","plt.xscale(\"log\")\n","plt.xlabel(\"Learning rate\")\n","plt.ylabel(\"Loss\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m~/util/example.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_resnet50.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfound_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m params = OrderedDict(\n\u001b[1;32m      4\u001b[0m     \u001b[0mlr_tuning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["model.load_state_dict(torch.load(\"model_resnet50.pth\"))\n","found_lr = 0.001\n","params = OrderedDict(\n","    lr_tuning=[50, 100, 200], batch_size=[64], shuffle=[True], device=[\"cuda\"],\n",")\n","\n","\n","def printnorm(self, input, output):\n","    # input is a tuple of packed inputs\n","    # output is a Tensor. output.data is the Tensor we are interested\n","    print(\"Inside \" + self.__class__.__name__ + \" forward\")\n","    print(\"\")\n","    print(\"input: \", type(input))\n","    print(\"input[0]: \", type(input[0]))\n","    print(\"output: \", type(output))\n","    print(\"\")\n","    print(\"input size:\", input[0].size())\n","    print(\"output size:\", output.data.size())\n","    print(\"output norm:\", output.data.norm())\n","\n","\n","# train for a few epochs that update only the classifier\n","optimizer = optim.Adam(model.parameters(), lr=found_lr)\n","train(\n","    model,\n","    optimizer,\n","    loss_fn,\n","    esc50_train_loader,\n","    esc50_val_loader,\n","    epochs=5,\n","    device=\"cuda\",\n",")\n","\n","epochs = 20\n","manager = RunManager(log_dir=\"test\")\n","\n","for run in RunBuilder.get_runs(params):\n","    model.to(run.device)\n","    esc50_train_loader = torch.utils.data.DataLoader(\n","        esc50pre_train, run.batch_size, shuffle=run.shuffle\n","    )\n","    esc50_val_loader = torch.utils.data.DataLoader(\n","        esc50pre_val, run.batch_size, shuffle=run.shuffle\n","    )\n","\n","    optimizer = optim.Adam(\n","        [\n","            {\"params\": model.conv1.parameters()},\n","            {\"params\": model.bn1.parameters()},\n","            {\"params\": model.relu.parameters()},\n","            {\"params\": model.maxpool.parameters()},\n","            {\"params\": model.layer1.parameters(), \"lr\": found_lr / run.lr_tuning},\n","            {\"params\": model.layer2.parameters(), \"lr\": found_lr / run.lr_tuning},\n","            {\"params\": model.layer3.parameters(), \"lr\": found_lr / run.lr_tuning},\n","            {\"params\": model.layer4.parameters(), \"lr\": found_lr / run.lr_tuning},\n","            {\"params\": model.avgpool.parameters(), \"lr\": found_lr / run.lr_tuning},\n","            {\"params\": model.fc.parameters(), \"lr\": found_lr / (100 * run.lr_tuning),},\n","        ],\n","        lr=found_lr,\n","    )\n","    for param in model.parameters():\n","        param.requires_grad = True\n","\n","    manager.begin_run(run, model, esc50_train_loader, esc50_val_loader)\n","\n","    for epoch in range(epochs):\n","        manager.begin_epoch()\n","        model.train()\n","        for batch in esc50_train_loader:\n","\n","            images = batch[0].to(run.device)\n","            labels = batch[1].to(run.device)\n","            preds = model(images)  # Pass Batch\n","            loss = F.cross_entropy(preds, labels)  # Calculate Loss\n","            optimizer.zero_grad()  # Zero Gradients\n","            loss.backward()  # Calculate Gradients\n","            optimizer.step()  # Update Weights\n","\n","            manager.track_loss(loss, batch, is_train=True)\n","\n","        model.eval()\n","        with torch.no_grad():\n","            for batch in esc50_val_loader:\n","                images = batch[0].to(run.device)\n","                labels = batch[1].to(run.device)\n","                preds = model(images)  # Pass Batch\n","                loss = F.cross_entropy(preds, labels)  # Calculate Loss\n","\n","                manager.track_loss(loss, batch, is_train=False)\n","                manager.track_num_correct(preds, labels)\n","\n","        manager.end_epoch()\n","    manager.end_run()\n","manager.save(\"results\")\n"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}